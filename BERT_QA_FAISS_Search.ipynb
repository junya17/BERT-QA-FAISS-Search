{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\"\"\"\n",
        "This Python script demonstrates an advanced application of Natural Language Processing (NLP) using the BERT (Bidirectional Encoder Representations from Transformers) model, combined with the efficient similarity search capabilities of FAISS (Facebook AI Similarity Search). The primary objective of this script is to match a user's question to the closest available answer from a predefined set of question-answer pairs.\n",
        "\n",
        "The script follows these key steps:\n",
        "1. Import necessary libraries including transformers (for BERT), torch, numpy, and faiss-cpu.\n",
        "2. Define a list of question-answer pairs in Japanese, which will serve as the base knowledge for the script to pull answers from.\n",
        "3. Load the BERT model and tokenizer to convert text data into a format that's understandable and processable by the model.\n",
        "4. Vectorize each question-answer pair using BERT. This process converts text into numerical vectors that represent the semantic meaning of the text.\n",
        "5. Use FAISS to create an efficient similarity search index with the vectors.\n",
        "6. Implement a function to find the closest answer from the Q&A pairs for a new user question, utilizing the FAISS index for fast and efficient similarity search.\n",
        "\n",
        "This script showcases the integration of state-of-the-art NLP techniques with similarity search algorithms to create a tool that could potentially be used in various applications such as automated customer support, FAQ automation, and more.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "RGzrlec7pnF1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "id": "WllKo56Q2KX4"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers torch numpy faiss-cpu nltk"
      ],
      "metadata": {
        "id": "Qk0njXUs0aRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertModel, GPT2LMHeadModel, GPT2Tokenizer\n",
        "import torch\n",
        "import numpy as np\n",
        "import faiss\n"
      ],
      "metadata": {
        "id": "Yna38PTZ3H9_"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dyz5GyOdBfhd"
      },
      "outputs": [],
      "source": [
        "qa_pairs = [\n",
        "    \"質問: 「注文した商品をどのように追跡しますか？」 回答: 「注文番号と電子メールアドレスを使用して、当社のウェブサイト上で注文を追跡できます。」\",\n",
        "    \"質問: 「製品の返品方法は？」 回答: 「製品は購入後30日以内に返品することができます。返品するには、オンラインフォームを記入してください。」\",\n",
        "    \"質問: 「支払い方法にはどのようなものがありますか？」 回答: 「クレジットカード、デビットカード、PayPal、銀行振込を受け付けています。」\",\n",
        "    \"質問: 「配送料金はいくらですか？」 回答: 「配送料金はお住まいの地域によって異なります。詳細はお支払いページをご覧ください。」\",\n",
        "    \"質問: 「商品はどれくらいの日数で届きますか？」 回答: 「通常、商品の配送には3〜5営業日かかります。」\",\n",
        "    \"質問: 「カスタマーサポートに連絡する方法は？」 回答: 「カスタマーサポートには電話、メール、お問い合わせフォームで連絡できます。詳細はお問い合わせページをご覧ください。」\",\n",
        "    \"質問: 「商品が壊れて届いた場合、どうすれば良いですか？」 回答: 「壊れた商品の場合、カスタマーサポートに連絡し、交換または返金の手続きを行ってください。」\",\n",
        "    \"質問: 「商品の在庫状況はどこで確認できますか？」 回答: 「商品の在庫状況は製品ページで確認できます。在庫がある場合、数量が表示されます。」\",\n",
        "    \"質問: 「注文をキャンセルする方法は？」 回答: 「注文をキャンセルするには、注文番号を入力し、カスタマーサポートに連絡してください。」\",\n",
        "    \"質問: 「返品送料は誰が負担しますか？」 回答: 「返品送料は、壊れた商品または誤った商品が送られた場合を除き、お客様の負担となります。」\",\n",
        "    \"質問: 「商品の保証期間はどのくらいですか？」 回答: 「商品の保証期間は通常1年です。詳細は製品の保証ポリシーをご確認ください。」\"\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sentence_vector(sentence, model, tokenizer):\n",
        "    \"\"\"文のベクトル化を行う関数\"\"\"\n",
        "    inputs = tokenizer(sentence, return_tensors='pt', truncation=True, max_length=128)\n",
        "    outputs = model(**inputs)\n",
        "    sentence_vector = outputs.last_hidden_state.mean(dim=1).detach().numpy()\n",
        "    return sentence_vector.reshape(-1)\n"
      ],
      "metadata": {
        "id": "TvNBp7mshebt"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "20E1c2KjBaTm"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer, BertModel\n",
        "\n",
        "# BERTモデルとトークナイザーのロード\n",
        "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "def get_sentence_vector(sentence, model, tokenizer):\n",
        "    \"\"\"文のベクトル化を行う関数\"\"\"\n",
        "    inputs = tokenizer(sentence, return_tensors='pt', truncation=True, max_length=128)\n",
        "    outputs = model(**inputs)\n",
        "    sentence_vector = outputs.last_hidden_state.mean(dim=1).detach().numpy()\n",
        "    return sentence_vector\n",
        "\n",
        "# 各ペアをベクトル化\n",
        "vectors = [get_sentence_vector(pair, bert_model, bert_tokenizer) for pair in qa_pairs]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "HsU7DaqaC14b"
      },
      "outputs": [],
      "source": [
        "# FAISSを使用してベクトルデータベースを作成\n",
        "dim = vectors[0].shape[1]\n",
        "index = faiss.IndexFlatL2(dim)\n",
        "index.add(np.vstack(vectors))  # ベクトルを追加"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oH1mpGcFC4fl",
        "outputId": "dec1808e-a329-489d-8b98-7f685cf0f62c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "最も近い回答: 質問: 「支払い方法にはどのようなものがありますか？」 回答: 「クレジットカード、デビットカード、PayPal、銀行振込を受け付けています。」, 距離: 22.608619689941406\n"
          ]
        }
      ],
      "source": [
        "def search_closest_answer(query, model, tokenizer):\n",
        "    query_vector = get_sentence_vector(query, model, tokenizer)\n",
        "    D, I = index.search(query_vector, k=1)\n",
        "    closest_index = I[0][0]\n",
        "    return qa_pairs[closest_index], D[0][0]\n",
        "\n",
        "# ユーザーの質問\n",
        "user_question = \"支払い方法は何がありますか？\"\n",
        "closest_answer, distance = search_closest_answer(user_question, bert_model, bert_tokenizer)\n",
        "print(f\"最も近い回答: {closest_answer}, 距離: {distance}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}